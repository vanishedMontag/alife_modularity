{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_mMw1jKdhNI"
      },
      "source": [
        "Perform MNIST classification using Neural Netwroks and Convolutional Neural Networks.\n",
        "\n",
        "1) Use 10 iterations for training\n",
        "\n",
        "\n",
        "2) Show the training loss for both networks on the same plot\n",
        "\n",
        "\n",
        "3) Compare the test loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FgD2m0H5isxW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models,transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader\n",
        "import torchmetrics as tm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1VPvHJrXisxX"
      },
      "outputs": [],
      "source": [
        "# MNIST\n",
        "def mnist(batch_sz, valid_size=0.2, shuffle=True, random_seed=2000):\n",
        "    num_classes = 10\n",
        "    transform_train = transforms.Compose([\n",
        "                        transforms.RandomCrop(28, padding=4),\n",
        "                        transforms.ToTensor(),\n",
        "                    ])\n",
        "    \n",
        "    \n",
        "    transform_test = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                    ])\n",
        "    \n",
        "\n",
        "    # Training dataset\n",
        "    train_data = MNIST(root='./datasets', train=True, download=True, transform=transform_train)\n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    if shuffle == True:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_sz ,pin_memory=True)\n",
        "\n",
        "    # Test dataset\n",
        "    test_data = MNIST(root='./datasets', train=False, download=True, transform=transform_test)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                              batch_size=batch_sz, shuffle=False, pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7fbWYYmxisxX",
        "outputId": "2f213ca2-c1af-491f-cadd-870bdf782583"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x12b1f9b70>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_sz=64 # this is batch size i.e. the number of rows in a batch of data\n",
        "\n",
        "train_loader, test_loader=mnist(batch_sz) \n",
        "\n",
        "tl = iter(train_loader)\n",
        "batch = next(tl)\n",
        "\n",
        "\n",
        "plt.imshow(batch[0][6,:,:,:].squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FD6fwO1ddbEU"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels=1,num_classes=10) -> None:\n",
        "        super(CNN,self).__init__() # In the other tutorial he is using CNN and self within the super(CNN, self) brakets\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3),stride=(1,1),padding=(1,1))  #  3 -1 /2 ; 3 being the filter_size, with padding the image size stays the same\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size= (2,2), stride= (2,2))\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "        self._in = nn.Linear(16*7*7, 128)\n",
        "        self.lin_out = nn.Linear(128,num_classes) # change 128 to 16*7*7 for AC1\n",
        "\n",
        "\n",
        "    # Forward Pass\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Linear Model\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = torch.relu(self._in(x))\n",
        "        x = self.lin_out(x)\n",
        "            \n",
        "        return x\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "g1UzEgLpisxZ",
        "outputId": "16ab4958-2c09-4f8d-98a8-46a6e1570ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "F53mUju8isxZ",
        "outputId": "94bf13a8-3955-498c-cdb4-464da0f6e452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "# Model 2 Dim Testing\n",
        "model_2 = CNN().to(device=device)\n",
        "x = torch.randn(64,1,28,28)\n",
        "print(model_2(x).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VoZLvqS2isxa"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter: \n",
        "\n",
        "inputs = 784\n",
        "mm = 0\n",
        "batch_sz=64\n",
        "epoch_no = 3\n",
        "mini_batches = [64]\n",
        "learning_rates = [0.1,0.01,0.001,0.0001]\n",
        "learning_rates = learning_rates[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zQPXbzEqisxa"
      },
      "outputs": [],
      "source": [
        "# Data Option 1:\n",
        "\n",
        "def unbiased_data(batch_sz):\n",
        "    train_dataset = MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "    test_dataset = MNIST(root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_sz, shuffle=True)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_sz, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DfrI5cHjisxb"
      },
      "outputs": [],
      "source": [
        "# Training and Testing\n",
        "def var_training(data_bias=True,model=CNN(),type_CNN = True):\n",
        "    for mini_batch in mini_batches:\n",
        "        for learning_rate in learning_rates:\n",
        "            model_2 = model.to(device=device)\n",
        "        \n",
        "            # write to tensorboard\n",
        "            step = 0\n",
        "\n",
        "            if data_bias == True and type_CNN == True:\n",
        "                writer = SummaryWriter(f'runs/MNIST/CNN_rand_bs={mini_batch}_lr={learning_rate}')\n",
        "            elif data_bias == False and type_CNN == True:\n",
        "                writer = SummaryWriter(f'runs/MNIST/CNN_bias_bs={mini_batch}_lr={learning_rate}')\n",
        "            elif data_bias == True and type_CNN == False:\n",
        "                writer = SummaryWriter(f'runs/MNIST/NN_wS_rand_bs={mini_batch}_lr={learning_rate}')\n",
        "            else:\n",
        "                writer = SummaryWriter(f'runs/MNIST/NN_wS_bias_bs={mini_batch}_lr={learning_rate}')\n",
        "\n",
        "\n",
        "            # Loss and optimizer\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            optimizer = optim.SGD(model_2.parameters(), lr=learning_rate, momentum= mm)\n",
        "            scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer,gamma=0.9,verbose=False)\n",
        "\n",
        "            # generate new data\n",
        "\n",
        "            if data_bias == True:\n",
        "                train_loader, test_loader=mnist(mini_batch)\n",
        "\n",
        "            else:\n",
        "                train_loader, test_loader=unbiased_data(mini_batch)\n",
        "            \n",
        "            for epoch in range(epoch_no):\n",
        "                train_loss = 0\n",
        "                for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "                    data = data.to(device=device)\n",
        "                    targets = targets.to(device=device)\n",
        "\n",
        "                    if type_CNN == False:\n",
        "                        data = data.reshape(data.shape[0], -1)\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "                    # forwards\n",
        "                    logits = model_2(data)\n",
        "                    loss = criterion(logits, targets)\n",
        "                    train_loss += loss.item()\n",
        "\n",
        "\n",
        "                    # backward \n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    # scheduler.step()\n",
        "\n",
        "                    # Running Accuracy\n",
        "                    _, predictions = logits.max(1)\n",
        "                    num_corr = (predictions == targets).sum()\n",
        "                    running_acc = float(num_corr)/float(data.shape[0])\n",
        "                    \n",
        "                    writer.add_scalar(\"Training Loss\", loss, global_step = step) \n",
        "                    writer.add_scalar(\"Training Accuracy\", running_acc, global_step=step)\n",
        "                    step += 1  \n",
        "\n",
        "                scheduler.step()\n",
        "\n",
        "            acc_l = []\n",
        "\n",
        "            accuracy = tm.Accuracy()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                step_2 = 0\n",
        "                for batch_idx, (data, targets) in enumerate(test_loader):\n",
        "                    data = data.to(device=device)\n",
        "                    targets = targets.to(device=device)\n",
        "\n",
        "                    if type_CNN == False:\n",
        "                        data = data.reshape(data.shape[0], -1)\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "                    logits = model_2(data)\n",
        "                    t_loss = criterion(logits, targets)\n",
        "                    train_loss += loss.item()\n",
        "\n",
        "                    yhat = torch.argmax(logits, axis =1)\n",
        "\n",
        "                    acc = accuracy(yhat.to(\"cpu\"),targets.to(\"cpu\"))\n",
        "\n",
        "                    acc_l.append(acc)\n",
        "\n",
        "                    writer.add_scalar(\"Testing Loss\", t_loss, global_step = step_2) \n",
        "                    writer.add_scalar(\"Testing Accuracy\", acc, global_step=step_2)\n",
        "                    step_2 += 1\n",
        "\n",
        "            print(f'the accuracy on the test set for the batch size: {mini_batch} and learning rate: {learning_rate} is {np.mean(acc_l):.2f}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7GlV7rOUisxb",
        "outputId": "1173ae50-4a23-4ce5-f8ad-ae03d8e45896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the accuracy on the test set for the batch size: 64 and learning rate: 0.1 is 0.97\n",
            "the accuracy on the test set for the batch size: 64 and learning rate: 0.01 is 0.98\n"
          ]
        }
      ],
      "source": [
        "var_training(data_bias=True,model=CNN(),type_CNN=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW3_1_LT_Submission.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai_lab",
      "language": "python",
      "name": "ai_lab"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "d410fd81c9a0b51d0e53167c40a880776428168a003798fed6e3e9082ee009aa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
